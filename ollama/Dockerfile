# 파일 위치: orbiton-ai/ollama/Dockerfile

FROM ollama/ollama:latest  
# Ollama 공식 이미지

# RUN ollama pull llama3  
# LLaMA3 모델 다운로드 > (수정) ollama 실행 전 이므로 다운로드 불가로 주석처리 이후 수동작업 진행

EXPOSE 11434  
# Ollama 기본 포트 노출

CMD ["serve"]  
# Ollama 서버 실행
